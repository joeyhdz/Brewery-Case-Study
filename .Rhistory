ale_knn <- beer_predict %>% select(Brewery_id,beer_name, IBU, ABV, Style) %>%
group_by(Brewery_id) %>% filter(str_detect(Style, "Ale")) %>%
mutate(Style = "ale")
# view(ipa_knn)  # 374
# view(ale_knn) # 519
combine_knn <- full_join(ipa_knn, ale_knn)
# view(combine_knn)
# simple test to see if the data works together within the KNN function
my_beer_test <- data.frame(IBU = c(.05, .04, .043), ABV = c(.06, .055, .065))
knn(beer_predict[,c(7,8)], my_beer_test, beer_predict$Style, k = 3, prob = TRUE)
# viewing what matches each of these strings will return before filtering.
# (str_view_all(beer_predict$Style, 'Ale', match = TRUE))
# (str_view_all(beer_predict$Style, 'IPA', match = TRUE))
# creating test variable to call so we can see if the filter works
#test_ale_filter <- beer_predict %>% filter(str_detect(Style, 'Ale'))
#view(test_ale_filter$Style) # viewing the filter for effectiveness
# repeating the same process for the IPA
#test_ipa_filter <- beer_predict %>% filter(str_detect(Style, 'IPA'))
#view(test_ipa_filter$Style) # viewing the filter for effectiveness
# using both filters above to create one combo test filter
#test_combo_filter<- beer_predict %>% filter(str_detect(Style, 'IPA') | str_detect(Style, "Ale"))
#view(test_combo_filter$Style)
# creating the finalized data frame to use for test/train split etc.
# beer_predict_fin <- beer_predict %>% filter(str_detect(Style, 'IPA') | str_detect(Style, "Ale"))
# glimpse(beer_predict_fin)
################################### KNN Test Train original Model #########################
#checking dimensions to understand what our test/train will look like
# glimpse(beer_predict_fin)
# nrow(beer_predict_fin) # total 887 rows
# round(nrow(beer_predict_fin)*.3) # total 177
# set.seed(765)
# intrain <- sample(nrow(beer_predict_fin), round(nrow(beer_predict_fin)*.30))
# beer_train <- beer_predict_fin[intrain,]
# beer_test <- beer_predict_fin[-intrain,]
# setting up the classification
# classification <- knn(beer_train[,c(7,8)],
# beer_test[,c(7,8)],
# beer_train$Style,
# k = 3, prob = TRUE)
# setting up a passable data for confusion matrix
# u <- union(classification, beer_test$Style)
# t <- table(factor(classification, u), factor(beer_test$Style, u), dnn = c("Prediction", "Truth"))
# confusion matrix for more stats on the model
# confusionMatrix(t)
print(CM)
print(CM$overall)
print(CM$overall*100)
print(CM$overall*1000)
################################### KNN Test type 2 #########################
#checking dimensions to understand what our test/train will look like
# glimpse(beer_predict_fin)
# nrow(combine_knn) # total 893 rows
# round(nrow(combine_knn)*.3) # total 268
set.seed(765)
intrain <- sample(nrow(combine_knn), round(nrow(combine_knn)*.30))
beer_train <- combine_knn[intrain,]
beer_test <- combine_knn[-intrain,]
# setting up the classification
classification <- knn(beer_train[,c(3,4)],
beer_test[,c(3,4)],
beer_train$Style,
k = 3, prob = TRUE)
# setting up a passable data for confusion matrix
u <- union(classification, beer_test$Style)
t <- table(factor(classification, u), factor(beer_test$Style, u), dnn = c("Prediction", "Truth"))
# confusion matrix for more stats on the model
CM <- confusionMatrix(t)
beer_knn_plot <- as.data.frame(CM$table)
beer_knn_plot$Prediction <- factor(beer_knn_plot$Prediction, levels = rev(levels(beer_knn_plot$Truth)))
ggplot(beer_knn_plot, aes(Prediction, Truth, fill = (Freq))) +
geom_tile(show.legend = FALSE) + geom_text(aes(label = (Freq))) +
scale_fill_gradient(low = "light blue", high = "#009194") +
labs(x = "Truth", y = "Prediction") +
scale_x_discrete(labels = c("IPA", "Ale")) +
scale_y_discrete(labels = c("Ale", "IPA"))+
coord_flip()+
ggtitle("Confusion Matrix Categorizing Model Predictions Against Actual Values")
print(round(CM$overall,2))
print(round(CM$overall[1],2))
print(CM$byClass)
print(CM$byClass[1,2])
print(CM$byClass[1:2,])
print(CM$byClass[,1:2])
print(CM$byClass[1])
print(CM$byClass[2])
print(c(CM$byClass[1], 'hello')
print(round(CM$overall[1],2))
print(round(CM$overall[1],2))
print(c(CM$byClass[1], 'hello')
print(CM$byClass[2])
print(c(CM$byClass[1], 'hello'))
print(c(CM$byClass[1], 'hello', collapse('')))
print(c(CM$byClass[1], 'hello'), collapse(' ')
print(c(CM$byClass[1], 'hello'), collapse(' '))
print(c(CM$byClass[1], 'hello'), collapse(' '))
?c()
cat(CM$overall[1], CM$byClass[1], CM$byClass[2])
cat(CM$overall[1]*100, CM$byClass[1], CM$byClass[2])
cat(CM$overall[1]*100, CM$byClass[1]*100, CM$byClass[2]*100)
cat('Accuracy:'CM$overall[1]*100, CM$byClass[1]*100, CM$byClass[2]*100)
cat('Accuracy:',CM$overall[1]*100, CM$byClass[1]*100, CM$byClass[2]*100)
cat('Accuracy:',CM$overall[1]*100, "\n"CM$byClass[1]*100, CM$byClass[2]*100)
cat('Accuracy:',CM$overall[1]*100, "\n",CM$byClass[1]*100, CM$byClass[2]*100)
print(CM$byClass[1])
cat('Accuracy:',CM$overall[1]*100, "\nSensitivity:",CM$byClass[1]*100, CM$byClass[2]*100)
cat('Accuracy:',CM$overall[1]*100, "\nSensitivity:",CM$byClass[1]*100, "\nSpecificity:",CM$byClass[2]*100)
cat('Accuracy:',CM$overall[1]*100,"%", "\nSensitivity:",CM$byClass[1]*100, "\nSpecificity:",CM$byClass[2]*100)
cat('Accuracy:',CM$overall[1]*100,"%", "\nSensitivity:",CM$byClass[1]*100, "%", "\nSpecificity:",CM$byClass[2]*100, "%")
print(CM$byClass[2])
# create the ABV map
abv_state_plot <- plot_usmap(data = state_medians[,1:3],
values = "median_abv",
color = "black",
labels = F) +
guides(fill = "none") +
geom_text(data = median_labels, aes(
x = x, y = y,
label = scales::number(median_abv * 100, accuracy = 0.01)), color = "black") +
scale_fill_gradient(low = "white", high = "red") +
labs(title = "Distribution of Median ABV per State", x = 'hello')
# create the ABV map
abv_state_plot <- plot_usmap(data = state_medians[,1:3],
values = "median_abv",
color = "black",
labels = F) +
guides(fill = "none") +
geom_text(data = median_labels, aes(
x = x, y = y,
label = scales::number(median_abv * 100, accuracy = 0.01)), color = "black") +
scale_fill_gradient(low = "white", high = "red") +
labs(title = "Distribution of Median ABV per State", x = 'hello')
# plot the ABV Median state plot
abv_state_plot
# create the ABV map
abv_state_plot <- plot_usmap(data = state_medians[,1:3],
values = "median_abv",
color = "black",
labels = F) +
guides(fill = "none") +
geom_text(data = median_labels, aes(
x = x, y = y,
label = scales::number(median_abv * 100, accuracy = 0.01)), color = "black") +
scale_fill_gradient(low = "white", high = "red") +
labs(title = "Distribution of Median ABV per State")
# plot the ABV Median state plot
abv_state_plot
# plot Median IBU
state_medians %>% ggplot(aes(x = reorder(state, desc(median_ibu)), y = median_ibu, fill = state))+
geom_bar(stat = 'identity', show.legend = FALSE) +
coord_flip() +
ggtitle("Bar plot of Median Values for each State")+
xlab("State by Abbreviation")
# plot Median IBU
state_medians %>% ggplot(aes(x = reorder(state, desc(median_ibu)), y = median_ibu, fill = state))+
geom_bar(stat = 'identity', show.legend = FALSE) +
coord_flip() +
ggtitle("Bar plot of Median Values for each State")+
xlab("State by Abbreviation")+
ylab("Median International Bitterness Units (IBU)")
# plot the ABV Median state plot
abv_state_plot
# plot the IBU Median state plot
ibu_state_plot
# plot Median ABV
state_medians %>% ggplot(aes(x = reorder(state, desc(median_abv)), y = median_abv, fill = state))+
geom_bar(stat='identity', show.legend = FALSE)+
coord_flip() +
ggtitle("Bar Plot of Median ABV Values for each State") +
xlab("State by Abbreviation")+
ylab("Median Value of Alcohol by Volume in Percent")
# plot Median ABV
state_medians %>% ggplot(aes(x = reorder(state, desc(median_abv)), y = median_abv*100, fill = state))+
geom_bar(stat='identity', show.legend = FALSE)+
coord_flip() +
ggtitle("Bar Plot of Median ABV Values for each State") +
xlab("State by Abbreviation")+
ylab("Median Value of Alcohol by Volume in Percent")
# plot Median ABV
state_medians %>% ggplot(aes(x = reorder(state, desc(median_abv)), y = median_abv*100, fill = state))+
geom_bar(stat='identity', show.legend = FALSE)+
coord_flip() +
ggtitle("Bar Plot of Median Alcohol by Volume (ABV) Values for each State") +
xlab("State by Abbreviation")+
ylab("Median Value of Alcohol by Volume in Percent")
################################### Question 4 ##################################
# this will return medians for each state ( NA NOT INCLUDED )
state_medians <- beer_brew %>% group_by(State) %>%
summarise(num_brew = n_distinct(Brew_name),
median_abv = median(ABV, na.rm = TRUE), median_ibu = median(IBU, na.rm = TRUE)) %>%
arrange(desc(num_brew))
# to return the medians data
# state_medians
# convert to data frame
state_medians <- as.data.frame(state_medians)
# convert variable column from S to s (upper to lower) so that it works with data in next question
names(state_medians)[1] <- 'state'
# plot Median ABV
state_medians %>% ggplot(aes(x = reorder(state, desc(median_abv)), y = median_abv*100, fill = state))+
geom_bar(stat='identity', show.legend = FALSE)+
coord_flip() +
ggtitle("Bar Plot of Median Alcohol by Volume (ABV) Values for each State") +
xlab("State by Abbreviation")+
ylab("Median Value of Alcohol by Volume in Percent")
# plot Median IBU
state_medians %>% ggplot(aes(x = reorder(state, desc(median_ibu)), y = median_ibu, fill = state))+
geom_bar(stat = 'identity', show.legend = FALSE) +
coord_flip() +
ggtitle("Bar plot of Median IBU Values for each State")+
xlab("State by Abbreviation")+
ylab("Median International Bitterness Units (IBU)")
# creating a variable to call for median labels
median_labels <- merge(centroid_labels, state_medians, by ='state')
# create the ABV map
abv_state_plot <- plot_usmap(data = state_medians[,1:3],
values = "median_abv",
color = "black",
labels = F) +
guides(fill = "none") +
geom_text(data = median_labels, aes(
x = x, y = y,
label = scales::number(median_abv * 100, accuracy = 0.01)), color = "black") +
scale_fill_gradient(low = "white", high = "red") +
labs(title = "Distribution of Median ABV per State")
# create the IBU map
ibu_state_plot <- plot_usmap(data = state_medians[,1:4],
values = "median_ibu",
color = "black",
labels = F)+
guides(fill = "none")+
geom_text(data = median_labels, aes(
x = x, y = y,
label = scales::number(median_ibu, accuracy = 1)), color = "black") +
scale_fill_gradient(low = "white", high = "red")+
labs(title = "Distribution of Median IBU per State")
# plot the ABV Median state plot
abv_state_plot
# plot the IBU Median state plot
ibu_state_plot
################################### Question 1 ##################################
# this gets only one brewery name so that we don't have multiple brew representation because
# of the multiple drinks served by that one location.
state_num_data <- beer_brew[!duplicated(beer_brew$Brew_name),]
# the n_distinct takes care of the potential repeat brew representation making last line redundant
# but kept in as precautionary measure.
state_brew_plot <- state_num_data %>% group_by(State) %>%
summarise(num_brew = n_distinct(Brew_name),
mean_abv = mean(ABV), mean_ibu = mean(IBU)) %>%
arrange(desc(num_brew))
# changes column State to state to satisfy the usmap argument
names(state_brew_plot)[1] <- 'state'
# makes into dataframe
state_brew_plot <- as.data.frame(state_brew_plot)
# plot of the Concentration of Breweries in the US
plot_usmap(data=state_brew_plot[,1:2],
regions = "states",
labels = TRUE,label_color = "black",
values = "num_brew") +
scale_fill_gradient(low = 'white', high = 'red')+
labs(title = 'Distribution of Breweries across the United States',
fill = "Brewery \nAmount") +
theme(legend.position = "right")
# SECONDARY MAP TO DISPLAY ACTUAL REPRESENTAION OF NUMERICAL VALUE PER EACH STATE
# get centroids
centroid_labels <- usmapdata::centroid_labels("states")
names(centroid_labels)[4] <- 'state'
# join data to centroids (using lat/long as coord. for state centers on map plot)
data_labels <- merge(centroid_labels, state_brew_plot, by = "state")
# create US map with centroids and lat/long as the label
brews_per_state <- plot_usmap(data = state_brew_plot[,1:2],
values = "num_brew",
color = "black",
labels = F) +
guides(fill = "none") +
geom_text(data = data_labels,aes(x = x, y = y,
label = scales::number(num_brew, accuracy = 1)),color = "black")+
scale_fill_gradient(low = "white", high = "red") +
labs(title = "Distribution of Breweries Across The United States",
fill = "Brewery \nAmount") +
theme(legend.position = "right")
brews_per_state
# table for display in RMD file
kable(state_num_data %>% group_by(State) %>%
summarise(num_brew = n_distinct(Brew_name),
mean_abv = mean(ABV), mean_ibu = mean(IBU)) %>%
arrange(desc(num_brew)))
library(tidyverse)
library(ggplot2)
library(janitor)
library(usmap)
library(caret)
library(e1071)
library(class)
library(knitr)
library(ggthemes)
beer_data <-read.csv("C:/Users/Joey/Desktop/DDS_Work/Unit - 8/Beers.csv")
brew_data <- read.csv("C:/Users/Joey/Desktop/DDS_Work/Unit - 8/Breweries.csv")
head(beer_brew)
library(tidyverse)
library(ggplot2)
library(janitor)
library(usmap)
library(caret)
library(e1071)
library(class)
library(knitr)
library(ggthemes)
beer_data <-read.csv("C:/Users/Joey/Desktop/DDS_Work/Unit - 8/Beers.csv")
brew_data <- read.csv("C:/Users/Joey/Desktop/DDS_Work/Unit - 8/Breweries.csv")
#################### Exploring Raw Data ###########################
# check rows and columns
# head(beer_data)
# head(brew_data)
# rename columns for merging
names(beer_data)[1] <- 'beer_name'
names(brew_data)[2] <- 'Brew_name'
names(brew_data)[1]<- 'Brewery_id'
# checking for missing values beer
# sapply(beer_data,function(x) sum(is.na(x))/nrow(beer_data))
# sapply(beer_data,function(x) sum(x== ""))
# checking for missing values brew
# sapply(brew_data,function(x) sum(is.na(x))/nrow(brew_data))
# sapply(brew_data,function(x) sum(x== ""))
# addressing the missing values from beer
beer_data[854,'Style'] = "Scottish Ale"
beer_data[867, 'Style'] = 'Marzen'
# looking for duplicates in data
# brew_data %>% get_dupes(Brewery_id)
# brew_data %>% get_dupes(Brew_name)
# beer_data %>% get_dupes(beer_name)
# beer_data %>% get_dupes(Brewery_id)
# beer_data %>% get_dupes(Beer_ID)
# addresses the duplicates in brew_data
brew_data<- brew_data[-c(96,378,262,139),]
# addresses the duplicates in beer_data
beer <- beer_data[!duplicated(beer_data$beer_name),]
# beer %>% get_dupes(Brewery_id) # these duplicates are for various drinks from the same brew id
# beer %>% get_dupes(Beer_ID) # fixed
# beer %>% get_dupes(beer_name)
# gets rid of the white space before the State abb.
brew_data$State<-trimws(brew_data$State, "left")
# merging beer and brew_data - with an inner join
beer_brew <- merge(brew_data, beer, by ='Brewery_id')
################################### Question 1 ##################################
# this gets only one brewery name so that we don't have multiple brew representation because
# of the multiple drinks served by that one location.
state_num_data <- beer_brew[!duplicated(beer_brew$Brew_name),]
# the n_distinct takes care of the potential repeat brew representation making last line redundant
# but kept in as precautionary measure.
state_brew_plot <- state_num_data %>% group_by(State) %>%
summarise(num_brew = n_distinct(Brew_name),
mean_abv = mean(ABV), mean_ibu = mean(IBU)) %>%
arrange(desc(num_brew))
# changes column State to state to satisfy the usmap argument
names(state_brew_plot)[1] <- 'state'
# makes into dataframe
state_brew_plot <- as.data.frame(state_brew_plot)
# plot of the Concentration of Breweries in the US
plot_usmap(data=state_brew_plot[,1:2],
regions = "states",
labels = TRUE,label_color = "black",
values = "num_brew") +
scale_fill_gradient(low = 'white', high = 'red')+
labs(title = 'Distribution of Breweries across the United States',
fill = "Brewery \nAmount") +
theme(legend.position = "right")
# SECONDARY MAP TO DISPLAY ACTUAL REPRESENTAION OF NUMERICAL VALUE PER EACH STATE
# get centroids
centroid_labels <- usmapdata::centroid_labels("states")
names(centroid_labels)[4] <- 'state'
# join data to centroids (using lat/long as coord. for state centers on map plot)
data_labels <- merge(centroid_labels, state_brew_plot, by = "state")
# create US map with centroids and lat/long as the label
brews_per_state <- plot_usmap(data = state_brew_plot[,1:2],
values = "num_brew",
color = "black",
labels = F) +
guides(fill = "none") +
geom_text(data = data_labels,aes(x = x, y = y,
label = scales::number(num_brew, accuracy = 1)),color = "black")+
scale_fill_gradient(low = "white", high = "red") +
labs(title = "Distribution of Breweries Across The United States",
fill = "Brewery \nAmount") +
theme(legend.position = "right")
brews_per_state
# table for display in RMD file
kable(state_num_data %>% group_by(State) %>%
summarise(num_brew = n_distinct(Brew_name),
mean_abv = mean(ABV), mean_ibu = mean(IBU)) %>%
arrange(desc(num_brew)))
head(beer_brew)
tail(beer_brew)
head(beer_brew)
tail(beer_brew)
################################### KNN Test type 2 #########################
#checking dimensions to understand what our test/train will look like
# glimpse(beer_predict_fin)
# nrow(combine_knn) # total 893 rows
# round(nrow(combine_knn)*.3) # total 268
set.seed(765)
intrain <- sample(nrow(combine_knn), round(nrow(combine_knn)*.30))
################################### KNN Prediction Model Data #########################
# test to see how the model will work using beer_brew
# make a Dataframe without NA so that we can run KNN:
beer_predict <- na.omit(beer_brew)
# sanity check
#view(beer_predict)
# creating a data frame that can be used to minimize the noise between Ale and IPA
ipa_knn <- beer_predict %>% select(Brewery_id,beer_name, IBU, ABV, Style) %>%
group_by(Brewery_id) %>% filter(str_detect(Style, "IPA")) %>%
mutate(Style = "ipa")
ale_knn <- beer_predict %>% select(Brewery_id,beer_name, IBU, ABV, Style) %>%
group_by(Brewery_id) %>% filter(str_detect(Style, "Ale")) %>%
mutate(Style = "ale")
# view(ipa_knn)  # 374
# view(ale_knn) # 519
combine_knn <- full_join(ipa_knn, ale_knn)
# view(combine_knn)
# simple test to see if the data works together within the KNN function
# my_beer_test <- data.frame(IBU = c(.05, .04, .043), ABV = c(.06, .055, .065))
# knn(beer_predict[,c(7,8)], my_beer_test, beer_predict$Style, k = 3, prob = TRUE)
# viewing what matches each of these strings will return before filtering.
# (str_view_all(beer_predict$Style, 'Ale', match = TRUE))
# (str_view_all(beer_predict$Style, 'IPA', match = TRUE))
# creating test variable to call so we can see if the filter works
#test_ale_filter <- beer_predict %>% filter(str_detect(Style, 'Ale'))
#view(test_ale_filter$Style) # viewing the filter for effectiveness
# repeating the same process for the IPA
#test_ipa_filter <- beer_predict %>% filter(str_detect(Style, 'IPA'))
#view(test_ipa_filter$Style) # viewing the filter for effectiveness
# using both filters above to create one combo test filter
#test_combo_filter<- beer_predict %>% filter(str_detect(Style, 'IPA') | str_detect(Style, "Ale"))
#view(test_combo_filter$Style)
# creating the finalized data frame to use for test/train split etc.
# beer_predict_fin <- beer_predict %>% filter(str_detect(Style, 'IPA') | str_detect(Style, "Ale"))
# glimpse(beer_predict_fin)
################################### KNN Test type 2 #########################
#checking dimensions to understand what our test/train will look like
# glimpse(beer_predict_fin)
# nrow(combine_knn) # total 893 rows
# round(nrow(combine_knn)*.3) # total 268
set.seed(765)
intrain <- sample(nrow(combine_knn), round(nrow(combine_knn)*.30))
beer_train <- combine_knn[intrain,]
beer_test <- combine_knn[-intrain,]
# setting up the classification
classification <- knn(beer_train[,c(3,4)],
beer_test[,c(3,4)],
beer_train$Style,
k = 3, prob = TRUE)
# setting up a passable data for confusion matrix
u <- union(classification, beer_test$Style)
t <- table(factor(classification, u), factor(beer_test$Style, u), dnn = c("Prediction", "Truth"))
# confusion matrix for more stats on the model
CM <- confusionMatrix(t)
beer_knn_plot <- as.data.frame(CM$table)
beer_knn_plot$Prediction <- factor(beer_knn_plot$Prediction, levels = rev(levels(beer_knn_plot$Truth)))
ggplot(beer_knn_plot, aes(Prediction, Truth, fill = (Freq))) +
geom_tile(show.legend = FALSE) + geom_text(aes(label = (Freq))) +
scale_fill_gradient(low = "light blue", high = "#009194") +
labs(x = "Truth", y = "Prediction") +
scale_x_discrete(labels = c("IPA", "Ale")) +
scale_y_discrete(labels = c("Ale", "IPA"))+
coord_flip()+
ggtitle("Confusion Matrix Categorizing Model Predictions Against Actual Values")
cat('Accuracy:',CM$overall[1]*100,"%",
"\nSensitivity:",CM$byClass[1]*100, "%",
"\nSpecificity:",CM$byClass[2]*100, "%")
################################### KNN finding best K #########################
iterations = 50
num_of_k = 50
split_percent = .3
model_accuracy = matrix(nrow = iterations, ncol = num_of_k)
model_specificity = matrix(nrow = iterations, ncol = num_of_k)
model_sensitivity = matrix(nrow = iterations, ncol = num_of_k)
for (j in 1:iterations)
{
set.seed(765)
intrain2 <- sample(nrow(combine_knn), round(nrow(combine_knn)*split_percent))
train2 <- combine_knn[intrain2,]
test2 <- combine_knn[-intrain2,]
for(i in 1:num_of_k)
{
classify = knn(train2[,c(3,4)],
test2[,c(3,4)],
train2$Style,
k = i, prob = TRUE)
u = union(classify, test2$Style)
t = table(factor(classify, u), factor(test2$Style, u))
CM = confusionMatrix(t)
model_accuracy[j,i] = CM$overall[1]
model_specificity[j,i] = CM$byClass[1]
model_sensitivity[j,i] = CM$byClass[2]
}
}
mean_accuracy = colMeans(model_accuracy)
# to determine which level of k provided the best accuracy so that we can tune the model if needed
# which.max(mean_accuracy)
mean_specificity = colMeans(model_specificity)
mean_sensitivity = colMeans(model_sensitivity)
plot(seq(1,num_of_k,1),
mean_accuracy, type = "l",
xlab = "Kth value 1:50",
ylab = "Mean value of measured Accuracy")
plot(seq(1, num_of_k, 1),
mean_specificity,
type = 'l',
xlab = "Kth value 1:50",
ylab = "Mean value of measured Specificity")
plot(seq(1, num_of_k, 1),
mean_sensitivity, type = 'l',
xlab = "Kth value 1:50",
ylab = "Mean value of measured Sensitivity")
